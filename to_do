Задача на Spark.

Есть следующие источники данных:

1. Логи clickstream вида:
=============================================================
timestamp	url	login	region_code
1576022400	http://yandex.ru	vasya	77
1576022412	http://google.ru	vasya	77
1576022435	http://shop.ru/goods/iphonex	petya	59
1576022500	http://yandex.ru	vika	59
1576022412	http://google.ru	sveta	77
1576022435	http://shop.ru/goods/iphonex	kolya	59
1576022500	http://shop.ru/goods/iphonex	vika	59
1576022700	http://google.ru	vika	59
1576022412	http://yandex.ru	sveta	77
1576022635	http://food-shop	kolya	59
1576022900	http://sports-wiki.ru/apple/	kolya	59
1576022400	http://yandex.ru	vasya	77
1576022412	http://google.ru	vasya	77
1576022435	http://shop.ru/goods/iphonex	vasya	77

=============================================================
Разделитель колонок - '\t'
Разделитель строк - '\n'
Количество строк - несколько миллионов
Файлов логов несколько, данные за один день


2. Справочник регионов
=============================================================
regione_code	mrf
45	ural
59	ural
31	center
32	center
77	center
...
...
=============================================================
Разделитель колонок - '\t'
Разделитель строк - '\n'
Количество строк - несколько десятков(до 100)


3. Категории сайтов.
=============================================================
url	category
http://yandex.ru	search
http://google.ru	search
http://shop.ru/goods/iphonex	shop
http://food-shop.ru/apple/	shop
http://sports-wiki.ru/apple/	sport
...
...
=============================================================
Разделитель колонок - '\t'
Разделитель строк - '\n'
Количество строк - несколько десятков(до 100)



Задача:

1. Получить следующие наборы данных:
 - логи clickstream обогащенные mrf из справочника регионов
 - пользователь с полем first_session - первый заход пользователя в сутки (timestamp)
 - логин, дата, popular_category - самая популярная по количеству посещений категория за день у каждого логина, если их несколько, то добавить одну любую.
2. Предложить набор метрик и их расчеты для источника данных - логи clickstream, которые будут максимально гарантировать валидность.
3. Оценить сложность (в терминах О-большое) алгоритмов расчета витрин данных в п.1


=============================================================


Требования:

Реализовать задачу при помощи фреймворка Spark, язык Scala.
Написать тесты.
Предоставить код всего проекта, включая тесты, можно ссылку на репозиторий



Есть есть вопросы, можно задавать.





